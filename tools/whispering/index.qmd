---
title: "Whispering"
date: "2025-11-26"
description: "Record a quick note, run Whisper in your browser with transformers.js + WebGPU, and copy the transcript."
categories: [tools, audio]
page-layout: full
toc: false
freeze: false
aliases: ["/posts/whispering/"]
---

Speak, transcribe, copy. Everything happens in-browser; no audio leaves the page.

```{=html}
<section class="whisper-pad" aria-live="polite">
  <div class="whisper-card">
    <header class="whisper-pad__header">
      <div class="stack">
        <p class="whisper-pad__kicker">Backend</p>
        <select id="backend-select" aria-label="Choose backend">
          <option value="webgpu">WebGPU (fastest, if supported)</option>
          <option value="wasm">WASM fallback</option>
        </select>
      </div>
      <div class="stack">
        <p class="whisper-pad__kicker">Model</p>
        <select id="model-select" aria-label="Choose model">
          <option value="Xenova/whisper-tiny.en">whisper-tiny.en (fastest)</option>
          <option value="Xenova/whisper-base.en">whisper-base.en (better)</option>
          <option value="Xenova/whisper-small.en">whisper-small.en (best, slowest)</option>
          <option value="Xenova/whisper-large-v3">whisper-large-v3 (very high quality, heavy)</option>
        </select>
      </div>
      <button id="load-model" type="button" class="ghost-btn">Load</button>
    </header>

    <div class="whisper-pad__status">
      <div class="whisper-pad__status-dot" aria-hidden="true"></div>
      <p id="status-text">Pick a backend and model, then load.</p>
    </div>

    <div class="whisper-pad__controls">
      <button id="record-btn" type="button" disabled>Record</button>
      <p class="whisper-pad__hint">We’ll ask for microphone access. Audio stays local.</p>
      <p class="whisper-pad__hint" id="support-note"></p>
      <p class="whisper-pad__hint">Tip: tiny ≈ fastest; small is higher quality; large-v3 is best but may be slow and need WebGPU.</p>
    </div>
  </div>

  <div class="whisper-card">
    <div class="whisper-pad__toolbar">
      <div class="pill-row">
        <span id="backend-pill" class="pill">Backend: –</span>
        <span id="model-pill" class="pill">Model: –</span>
      </div>
      <span id="timer" class="timer">00:00</span>
      <div class="whisper-pad__actions">
        <button id="copy-btn" type="button" disabled>Copy transcript</button>
        <button id="clear-btn" type="button" disabled>Clear</button>
      </div>
    </div>
    <div class="llm-row">
      <label class="toggle">
        <input type="checkbox" id="llm-toggle" checked />
        <span>Auto-fix punctuation (Llama 3.2 1B)</span>
      </label>
      <span id="llm-status" class="pill pill--muted">LLM: loading…</span>
    </div>
    <textarea id="transcript" rows="14" spellcheck="true" placeholder="Hit Record, speak, and the transcript will appear here." readonly></textarea>
  </div>
</section>
```

```{=html}
<script type="module">
  const backendSelect = document.getElementById('backend-select');
  const loadButton = document.getElementById('load-model');
  const modelSelect = document.getElementById('model-select');
  const recordButton = document.getElementById('record-btn');
  const copyButton = document.getElementById('copy-btn');
  const clearButton = document.getElementById('clear-btn');
  const statusText = document.getElementById('status-text');
  const supportNote = document.getElementById('support-note');
  const transcriptField = document.getElementById('transcript');
  const backendPill = document.getElementById('backend-pill');
  const modelPill = document.getElementById('model-pill');
  const timerEl = document.getElementById('timer');
  const llmToggle = document.getElementById('llm-toggle');
  const llmStatus = document.getElementById('llm-status');
  // Known-good ONNX chat model confirmed to load with transformers.js v3: ~1B params.
  const LLM_MODEL_ID = 'onnx-community/Llama-3.2-1B-Instruct-q4f16';

  const supportsWebGPU = typeof navigator !== 'undefined' && 'gpu' in navigator;
  let transcriber = null;
  let transformersModule = null;
  let llm = null;
  let llmLoading = false;
  let llmLoadPromise = null;
  let mediaRecorder = null;
  let recordedChunks = [];
  let timerId = null;
  let recordingStartedAt = null;

  initSupportNote();

  loadButton?.addEventListener('click', loadModel);
  recordButton?.addEventListener('click', toggleRecording);
  copyButton?.addEventListener('click', copyTranscript);
  clearButton?.addEventListener('click', () => {
    transcriptField.value = '';
    copyButton.disabled = true;
    clearButton.disabled = true;
  });

  autoLoadOnVisit();

  function initSupportNote() {
    if (!supportsWebGPU) {
      backendSelect.value = 'wasm';
      backendSelect.querySelector('option[value="webgpu"]').textContent = 'WebGPU (not detected)';
      backendSelect.querySelector('option[value="webgpu"]').disabled = true;
      supportNote.textContent = 'WebGPU not detected; using WASM. Try Chrome/Edge on desktop for GPU speed.';
    } else {
      supportNote.textContent = 'WebGPU detected. Leave backend on WebGPU unless it fails to load.';
    }
  }

  async function ensureTransformers() {
    if (transformersModule) return transformersModule;
    setStatus('Loading transformers.js…');
    const mod = await import('https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.8.0/dist/transformers.min.js');
    // CDN build sometimes ships UMD under default; unwrap as needed.
    transformersModule = mod?.pipeline ? mod : (mod?.default ?? mod);
    // expose globally for debugging parity with docs
    window.transformers = transformersModule;
    return transformersModule;
  }

  async function loadModel() {
    const { pipeline } = await ensureTransformers();
    const backend = backendSelect.value === 'webgpu' && supportsWebGPU ? 'webgpu' : 'wasm';
    const modelId = modelSelect.value;
    setStatus(`${backend === 'webgpu' ? 'Loading on WebGPU…' : 'Loading (WASM)…'} (${modelId.split('/').pop()})`);
    toggleBusy(true);
    backendPill.textContent = `Backend: ${backend.toUpperCase()}`;
    modelPill.textContent = `Model: ${modelId.split('/').pop()}`;

    try {
      transcriber = await pipeline('automatic-speech-recognition', modelId, {
        device: backend,
        // fp16 on WebGPU to avoid ORT dtype warnings; q8 on WASM for speed.
        dtype: backend === 'webgpu' ? 'fp16' : 'q8',
      });
      setStatus(`Ready (${modelId.split('/').pop()}). Hit Record and start speaking.`);
      recordButton.disabled = false;
    } catch (error) {
      console.error(error);
      setStatus(`Model load failed: ${error.message}`);
    } finally {
      toggleBusy(false);
    }
  }

  async function toggleRecording() {
    if (recordButton.classList.contains('is-recording')) {
      stopRecording();
      return;
    }

    if (!transcriber) {
      await loadModel();
      if (!transcriber) return;
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      recordedChunks = [];
      mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
      mediaRecorder.ondataavailable = (e) => recordedChunks.push(e.data);
      mediaRecorder.onstop = async () => {
        stream.getTracks().forEach((t) => t.stop());
        await transcribeAudio(new Blob(recordedChunks, { type: mediaRecorder.mimeType || 'audio/webm' }));
      };

      mediaRecorder.start();
      setStatus('Recording…');
      recordButton.textContent = 'Stop & transcribe';
      recordButton.classList.add('is-recording');
      startTimer();
    } catch (error) {
      console.error(error);
      setStatus(`Microphone error: ${error.message}`);
    }
  }

  function stopRecording() {
    if (!mediaRecorder) return;
    setStatus('Stopping and transcribing…');
    recordButton.disabled = true;
    mediaRecorder.stop();
    stopTimer();
  }

  async function transcribeAudio(blob) {
    try {
      toggleBusy(true);
      const floatPCM = await decodeToPCM(blob, 16000);
      const result = await transcriber(floatPCM, { return_timestamps: false });
      const rawText = (result?.text || '').trim();
      transcriptField.value = rawText;

      if (llmToggle?.checked) {
        setStatus('Transcribed. Polishing with Qwen3 0.6B…');
        const polished = await maybeRefineTranscript(rawText);
        if (polished) transcriptField.value = polished;
      }

      copyButton.disabled = !transcriptField.value;
      clearButton.disabled = !transcriptField.value;
      setStatus('Transcription finished.');
    } catch (error) {
      console.error(error);
      setStatus(`Transcription failed: ${error.message}`);
    } finally {
      recordButton.disabled = false;
      recordButton.textContent = 'Record again';
      recordButton.classList.remove('is-recording');
      toggleBusy(false);
    }
  }

  async function decodeToPCM(blob, targetSampleRate = 16000) {
    const arrayBuf = await blob.arrayBuffer();
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const decoded = await audioCtx.decodeAudioData(arrayBuf.slice(0));

    // If sample rate matches, return mono channel data directly.
    if (decoded.sampleRate === targetSampleRate) {
      return decoded.numberOfChannels > 1
        ? mergeToMono(decoded)
        : decoded.getChannelData(0);
    }

    // Resample via OfflineAudioContext.
    const offline = new OfflineAudioContext(1, Math.ceil(decoded.duration * targetSampleRate), targetSampleRate);
    const source = offline.createBufferSource();
    source.buffer = decoded;
    source.connect(offline.destination);
    source.start(0);
    const rendered = await offline.startRendering();
    return rendered.getChannelData(0);
  }

  function mergeToMono(buffer) {
    const ch0 = buffer.getChannelData(0);
    if (buffer.numberOfChannels === 1) return ch0;
    const ch1 = buffer.getChannelData(1);
    const out = new Float32Array(ch0.length);
    for (let i = 0; i < ch0.length; i++) {
      out[i] = (ch0[i] + ch1[i]) * 0.5;
    }
    return out;
  }

  async function copyTranscript() {
    try {
      await navigator.clipboard.writeText(transcriptField.value);
      copyButton.textContent = 'Copied!';
      setTimeout(() => (copyButton.textContent = 'Copy transcript'), 1000);
    } catch (error) {
      setStatus('Clipboard blocked. Select text manually to copy.');
    }
  }

  function setStatus(message) {
    statusText.textContent = message;
  }

  function toggleBusy(isBusy) {
    loadButton.disabled = isBusy;
    recordButton.disabled = isBusy || !transcriber;
    backendSelect.disabled = isBusy;
  }

  function startTimer() {
    recordingStartedAt = Date.now();
    updateTimer();
    timerId = setInterval(updateTimer, 200);
  }

  function stopTimer() {
    clearInterval(timerId);
    timerId = null;
    timerEl.textContent = '00:00';
    recordingStartedAt = null;
  }

  function updateTimer() {
    if (!recordingStartedAt) return;
    const elapsedMs = Date.now() - recordingStartedAt;
    const seconds = Math.floor(elapsedMs / 1000) % 60;
    const minutes = Math.floor(elapsedMs / 60000);
    timerEl.textContent = `${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')}`;
  }

  async function loadLLM() {
    if (llm) return llm;
    if (llmLoadPromise) return llmLoadPromise;
    if (!supportsWebGPU) {
      llmStatus && (llmStatus.textContent = 'LLM: needs WebGPU; disabled');
      llmToggle && (llmToggle.checked = false, llmToggle.disabled = true);
      return null;
    }
    llmLoading = true;
    llmStatus && (llmStatus.textContent = 'LLM: loading…');
    llmLoadPromise = (async () => {
      try {
        const { pipeline } = await ensureTransformers();
        const device = supportsWebGPU ? 'webgpu' : 'wasm';
        llm = await pipeline('text-generation', LLM_MODEL_ID, {
          device,
          // q4f16 weights; keep explicit to avoid fp32 fallback.
          dtype: 'q4f16',
        });
        llmStatus && (llmStatus.textContent = `LLM: ready (${device.toUpperCase()})`);
        return llm;
      } catch (error) {
        console.error(error);
        llmStatus && (llmStatus.textContent = 'LLM: failed to load');
        return null;
      } finally {
        llmLoading = false;
        llmLoadPromise = null;
      }
    })();

    return llmLoadPromise;
  }

  async function maybeRefineTranscript(text) {
    if (!llm) {
      await loadLLM();
      if (!llm) return text;
    }

    const messages = [
      {
        role: 'system',
        content: 'You fix punctuation, casing, and typos in short transcripts. Keep wording and meaning; return only the corrected text.',
      },
      { role: 'user', content: text },
    ];

    try {
      const output = await llm(messages, {
        max_new_tokens: 96,
        do_sample: false,
      });
      const cleaned = output?.[0]?.generated_text?.at(-1)?.content?.trim();
      return cleaned || text;
    } catch (error) {
      console.error(error);
      llmStatus && (llmStatus.textContent = 'LLM: error while generating');
      return text;
    }
  }

  function autoLoadOnVisit() {
    // Load both models on first paint so the first interaction is fast.
    loadModel();
    // Only pre-load LLM if WebGPU is present; otherwise keep it off.
    if (supportsWebGPU) loadLLM();
  }
</script>
```

```{=html}
<style>
  .whisper-pad {
    display: grid;
    gap: 1.5rem;
    align-items: start;
    width: min(100%, 72rem);
    margin-inline: auto;
    padding: 0.5rem;
  }

  @media (min-width: 768px) {
    .whisper-pad {
      grid-template-columns: repeat(2, minmax(0, 1fr));
    }
  }

  .whisper-card {
    display: flex;
    flex-direction: column;
    gap: 1rem;
    padding: 1.25rem;
    border-radius: 1rem;
    border: 1px solid var(--bs-border-color, #c5c5c5);
    background: var(--bs-body-bg, #fff);
    box-shadow: 0 10px 30px rgba(0, 0, 0, 0.04);
  }

  .whisper-pad__header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    gap: 1rem;
    flex-wrap: wrap;
  }

  .whisper-pad__kicker {
    font-size: 0.9rem;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    color: var(--bs-secondary-color, #555);
    margin: 0;
  }

  .stack {
    display: flex;
    flex-direction: column;
    gap: 0.25rem;
    min-width: 14rem;
  }

  select#backend-select {
    margin-top: 0.35rem;
    padding: 0.55rem 0.75rem;
    border-radius: 0.65rem;
    border: 1px solid var(--bs-border-color, #c5c5c5);
    background: var(--bs-body-bg, #fff);
    color: var(--bs-body-color, #111);
    min-width: 16rem;
  }

  select#model-select {
    padding: 0.55rem 0.75rem;
    border-radius: 0.65rem;
    border: 1px solid var(--bs-border-color, #c5c5c5);
    background: var(--bs-body-bg, #fff);
    color: var(--bs-body-color, #111);
    min-width: 16rem;
  }

  .ghost-btn {
    padding: 0.65rem 1.3rem;
    border-radius: 0.9rem;
    border: 1px solid var(--bs-border-color, #c5c5c5);
    background: linear-gradient(120deg, rgba(0, 0, 0, 0.04), rgba(0, 0, 0, 0.02));
    cursor: pointer;
  }

  .ghost-btn:disabled {
    opacity: 0.6;
    cursor: wait;
  }

  .whisper-pad__status {
    display: inline-flex;
    align-items: center;
    gap: 0.6rem;
    padding: 0.75rem 1rem;
    border-radius: 0.9rem;
    background: rgba(0, 0, 0, 0.03);
    border: 1px dashed var(--bs-border-color, #c5c5c5);
  }

  .whisper-pad__status-dot {
    width: 0.75rem;
    height: 0.75rem;
    border-radius: 999px;
    background: radial-gradient(circle at 50% 50%, #2ecc71, #16a085);
    box-shadow: 0 0 0.4rem rgba(46, 204, 113, 0.6);
  }

  .whisper-pad__controls {
    display: flex;
    flex-direction: column;
    gap: 0.5rem;
  }

  #record-btn {
    padding: 0.8rem 1.4rem;
    font-size: 1rem;
    border-radius: 0.9rem;
    border: none;
    color: #fff;
    background: linear-gradient(120deg, #111, #333);
    cursor: pointer;
    transition: transform 0.1s ease, box-shadow 0.2s ease;
  }

  #record-btn.is-recording {
    background: linear-gradient(120deg, #b20024, #ff4d4d);
    box-shadow: 0 0.7rem 1.5rem rgba(255, 77, 77, 0.25);
  }

  #record-btn:disabled {
    opacity: 0.6;
    cursor: not-allowed;
    box-shadow: none;
  }

  .whisper-pad__hint {
    margin: 0;
    font-size: 0.9rem;
    color: var(--bs-secondary-color, #555);
  }

  .whisper-pad__output {
    gap: 0.75rem;
  }

  .whisper-pad__toolbar {
    display: flex;
    align-items: center;
    justify-content: space-between;
    gap: 0.75rem;
    flex-wrap: wrap;
  }

  .pill-row {
    display: flex;
    gap: 0.5rem;
    flex-wrap: wrap;
  }

  .whisper-pad__actions {
    display: flex;
    gap: 0.5rem;
  }

  .pill {
    display: inline-flex;
    align-items: center;
    gap: 0.4rem;
    padding: 0.4rem 0.75rem;
    border-radius: 999px;
    background: rgba(0, 0, 0, 0.05);
    border: 1px solid var(--bs-border-color, #c5c5c5);
    font-size: 0.9rem;
  }

  .pill--muted {
    background: rgba(0, 0, 0, 0.04);
    color: var(--bs-secondary-color, #555);
  }

  .llm-row {
    display: flex;
    align-items: center;
    justify-content: space-between;
    gap: 0.75rem;
    flex-wrap: wrap;
  }

  .toggle {
    display: inline-flex;
    align-items: center;
    gap: 0.45rem;
    cursor: pointer;
    user-select: none;
    font-weight: 600;
  }

  .toggle input[type="checkbox"] {
    width: 1.2rem;
    height: 1.2rem;
    accent-color: #111;
    cursor: pointer;
  }

  .timer {
    font-variant-numeric: tabular-nums;
    font-weight: 700;
  }

  #transcript {
    width: 100%;
    min-height: 16rem;
    padding: 0.85rem 1rem;
    border-radius: 0.9rem;
    border: 1px solid var(--bs-border-color, #c5c5c5);
    background: var(--bs-body-bg, #fff);
    color: var(--bs-body-color, #111);
    font-family: "Courier New", monospace;
    font-size: 0.95rem;
    line-height: 1.5;
    resize: vertical;
  }

  .whisper-pad__actions button,
  #copy-btn,
  #clear-btn {
    padding: 0.45rem 0.9rem;
    border-radius: 0.75rem;
    border: 1px solid var(--bs-border-color, #c5c5c5);
    background: transparent;
    cursor: pointer;
  }

  .whisper-pad__actions button:disabled {
    opacity: 0.6;
    cursor: not-allowed;
  }

  @media (max-width: 600px) {
    .whisper-pad {
      grid-template-columns: 1fr;
    }

    #transcript {
      min-height: 14rem;
    }
  }
</style>
```
